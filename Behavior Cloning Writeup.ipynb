{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Network to Drive Car in Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution design approach\n",
    "\n",
    "In order to derive a good mode, I decided to start by collecting two big sets of data of driving forward 1 lap and driving in the opposite directions for 1 lap. Then I collect some data that guide the model to make the correct turn near the left edge and right edge of the road. \n",
    "\n",
    "Then I come up with some certain model and train it with the data I have. The, I spend time to test out the model and adding more data at specific location where the car behaves inconsistently or keeps getting stuck. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "######\n",
    "CENTER_IDX = 0\n",
    "LEFT_IDX = 1\n",
    "RIGHT_IDX = 2\n",
    "STEERING_ANGLE_IDX = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READ INPUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_file_name(file):\n",
    "    \"\"\"\n",
    "    Assume last backslash\n",
    "    \"\"\"\n",
    "    assert(file is not None)\n",
    "    name_start = file.rfind(\"/\")\n",
    "    return file[name_start+1:]\n",
    "\n",
    "\n",
    "def read_input_dir(folder_name, raw_inputs):\n",
    "    # OPEN data folder to read data\n",
    "    # load csv file\n",
    "    if not os.path.exists(folder_name):\n",
    "        raise Exception('folder %s does not exist' % folder_name)\n",
    "    with open(folder_name + \"/driving_log.csv\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for data in reader:\n",
    "            # extract name \n",
    "            center_img = os.path.join(folder_name+\"/IMG\", extract_file_name(data[CENTER_IDX]))\n",
    "            # append data \n",
    "            raw_inputs.append((center_img, float(data[STEERING_ANGLE_IDX])))\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STRATEGY FOR COLLECTING DATA \n",
    "\n",
    "My goal is to train a model be able to drive both easy and difficult routes. Therefore, I have been spending quite some amount of time to collect data especially for the difficult route. \n",
    "\n",
    "There are many spots on the difficult drive that the model does not behave so well that I had to collect much more data.\n",
    "\n",
    "In general, I also keep observing the model during the run to pickout the spot where it does not behave so well leading to the car get stuck and manually adding data for those specific location. \n",
    "\n",
    "I also spend time to collect a lot of data from each side fof the road in order to train the model to always steer toward the middle of the road as much as it can. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2797\n",
      "5893\n",
      "6867\n",
      "8360\n",
      "9330\n",
      "10560\n",
      "11652\n",
      "13738\n",
      "15090\n",
      "17296\n",
      "19448\n",
      "20140\n",
      "20513\n",
      "20777\n",
      "23199\n",
      "23879\n",
      "24726\n",
      "25983\n",
      "26379\n",
      "27810\n",
      "28962\n",
      "29867\n",
      "30976\n",
      "32037\n",
      "33830\n",
      "34264\n",
      "34526\n",
      "34840\n",
      "36225\n",
      "37168\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = []\n",
    "# read each data folder\n",
    "folder_list = [\n",
    "    \"../collect_data/drive_forward_data\",\n",
    "    \"../collect_data/drive_reverse_data\",\n",
    "    \"../collect_data/drive_left_data\",\n",
    "    \"../collect_data/drive_right_data\",\n",
    "    \"../collect_data2/side_drive_data_1\",\n",
    "    \"../collect_data2/side_drive_data2\",\n",
    "    \"../collect_data3/bridge_data\",\n",
    "    \"../collect_data4\",\n",
    "    \"../collect_data5\",\n",
    "    \"../diff_data/diff_data1\",\n",
    "    \"../diff_data/diff_data2\",\n",
    "    \"../diff_data/diff_data3\",\n",
    "    \"../diff_data/diff_data4\",\n",
    "    \"../diff_data/diff_data5\",\n",
    "    \"../diff_data/diff_data6\",\n",
    "    \"../diff_data2/diff_data7\",\n",
    "    \"../new_data/diff_data\",\n",
    "    \"../new_data/diff_data2\",\n",
    "    \"../new_data/diff_data3\",\n",
    "    \"../new_data/diff_dat4\",\n",
    "    \"../new_data/diff_data4\",\n",
    "    \"../new_data/diff_data5\",\n",
    "    \"../new_data/diff_data6\",\n",
    "    \"../new_data/diff_data7\",\n",
    "    \"../new_data/diff_data8\",\n",
    "    \"../new_data/diff_data9\",\n",
    "    \"../new_data/diff_data10\",\n",
    "    \"../new_data/diff_data11\",\n",
    "    \"../new_data/diff_data12\",\n",
    "    \"../new_data/diff_data13\"\n",
    "]\n",
    "\n",
    "# Read all data \n",
    "for each_folder in folder_list:\n",
    "    read_input_dir(each_folder, raw_inputs)\n",
    "    print (len(raw_inputs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and test dataset\n",
    "\n",
    "I use sklearn **train_test_split** to split the dataset into 80% training and 20% test with shuffle as default option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "from sklearn.model_selection import train_test_split\n",
    "raw_inputs = np.array(raw_inputs)\n",
    "train_raw_inputs, validation_raw_inputs = train_test_split(raw_inputs, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATOR FOR CREATE BATCH DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "# CENTEER\n",
    "def data_generator(raw_inputs, batch_size=32):\n",
    "    total_samples = len(raw_inputs)\n",
    "    print(raw_inputs.shape)\n",
    "    while 1:\n",
    "        for offset in range(0, total_samples, batch_size):\n",
    "            samples = raw_inputs[offset:offset+batch_size]\n",
    "            inputs = []\n",
    "            labels = []\n",
    "            for sample in samples:\n",
    "                if (not os.path.exists(sample[0])):\n",
    "                    print(\"Failed %s \" % sample[0])\n",
    "                inputs.append(cv2.cvtColor(cv2.imread(sample[0]), cv2.COLOR_BGR2RGB))\n",
    "                labels.append(sample[1])\n",
    "            X_train = np.array(inputs)\n",
    "            Y_train = np.array(labels)\n",
    "            yield shuffle(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT DATA AND CREATE GENERATOR\n",
    "\n",
    "Here I passed the training data set above to the **data_generator** function so we can use python generator feature to optimize memory usage better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(train_raw_inputs)\n",
    "validation_generator = data_generator(validation_raw_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NETWORK ARCHITECTURE AND TRAINING\n",
    "\n",
    "In order to come up with the final network archiecture, I have gone through an empirical process by first starting with a simple architecture and then gradually adding more layers as more data added to help the model be able to learn more features and not overfitting.\n",
    "\n",
    "The final model architecture include:\n",
    "- A lambda layers to normalize input data as neural network works better with small values between 0 to 1.\n",
    "- A cropping layer in order to extract only interested area of the image that related to making steering decision.\n",
    "- A convolution layer with 24 kernels of size 5x5 \n",
    "- A convolution layer with 36 kernels of size 5x5 \n",
    "- A convolution layer with 48 kernels of size 5x5\n",
    "- A convolution layer with 64 kernels of size 3x3\n",
    "- A convolution layer with 64 kernels of size 3x3\n",
    "- A linear dense layer of size 100\n",
    "- A linear dense layer of size 50\n",
    "- A linear dense layer of size 1 (final output values)\n",
    "\n",
    "\n",
    "In order to avoid overfitting, I have applied some well-known techniques:\n",
    "- For the first 3 convolution layers, I added the maxpool layer with kernel of size 2x2 to reduce complicated details and help the network train faster.\n",
    "- Each network layer outputs (except the last one) are activated with non-linear relu function.\n",
    "- Adding dropout layer between each network layers to help the network generalize better as well as train faster.\n",
    "- Using BatchNormalization layer also helps to reduce the affects of previous layer ouputs to the current layer inputs so the network can be trained faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dropout, MaxPooling2D, Dense, Lambda, Cropping2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    # normalize input \n",
    "    model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))\n",
    "    model.add(Cropping2D(cropping=((70,25),(0,0)))) \n",
    "    model.add(Conv2D(24, 5, 5,activation='relu', subsample=(2,2))) # input: 65x320x3, 31x158x3x16\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(p=0.2))\n",
    "    model.add(Conv2D(36, 5, 5,activation='relu',subsample=(2,2))) # input: 31x158x3x32, 13x76x3x32\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(p=0.2))\n",
    "    model.add(Conv2D(48, 5, 5,activation='relu',subsample=(2,2))) # input: 31x158x3x32, 13x76x3x32 \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(p=0.2))\n",
    "    model.add(Conv2D(64, 3, 3,activation='relu')) # input: 31x158x3x32, 13x76x3x32 \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(p=0.2))\n",
    "    model.add(Conv2D(64, 3, 3,activation='relu')) # input: 31x158x3x32, 13x76x3x32 \n",
    "    model.add(Dropout(p=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(p=0.4))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(p=0.4))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING PROCESS\n",
    "\n",
    "I set the number of epochs to be 100. In order to avoid overfit and saving time during training, I allow the model to be saved during the training  if there is improvement on validation loss. After about every 10 epochs, I take the best model and try it on the simulation and pick the model that is able to drive the whole lap without getting stuck.\n",
    "\n",
    "Then I test the model on the easy route to make sure that it also learnt to drive well with the easy one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"full_model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callback_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33451, 2)\n",
      "Epoch 1/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.5877 - acc: 0.3378- ETA: 0s - loss: 0.5899 - acc: (3717, 2)\n",
      "Epoch 00000: val_loss improved from inf to 0.16557, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 57s - loss: 0.5876 - acc: 0.3379 - val_loss: 0.1656 - val_acc: 0.4539\n",
      "Epoch 2/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1850 - acc: 0.4290Epoch 00001: val_loss improved from 0.16557 to 0.14551, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1850 - acc: 0.4291 - val_loss: 0.1455 - val_acc: 0.4894\n",
      "Epoch 3/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.4447Epoch 00002: val_loss improved from 0.14551 to 0.14006, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1690 - acc: 0.4448 - val_loss: 0.1401 - val_acc: 0.4961\n",
      "Epoch 4/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1639 - acc: 0.4496- ETA: Epoch 00003: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.1639 - acc: 0.4497 - val_loss: 0.1401 - val_acc: 0.4977\n",
      "Epoch 5/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.4548- ETA: 1s - lossEpoch 00004: val_loss improved from 0.14006 to 0.13550, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1602 - acc: 0.4549 - val_loss: 0.1355 - val_acc: 0.5017\n",
      "Epoch 6/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1565 - acc: 0.4607Epoch 00005: val_loss improved from 0.13550 to 0.13340, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1565 - acc: 0.4608 - val_loss: 0.1334 - val_acc: 0.5085\n",
      "Epoch 7/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1531 - acc: 0.4640Epoch 00006: val_loss improved from 0.13340 to 0.13093, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1531 - acc: 0.4640 - val_loss: 0.1309 - val_acc: 0.5120\n",
      "Epoch 8/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.4685Epoch 00007: val_loss improved from 0.13093 to 0.12942, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1506 - acc: 0.4686 - val_loss: 0.1294 - val_acc: 0.5155\n",
      "Epoch 9/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.4726Epoch 00008: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.1479 - acc: 0.4728 - val_loss: 0.1342 - val_acc: 0.5101\n",
      "Epoch 10/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.4776- ETA: 1s - loss:Epoch 00009: val_loss improved from 0.12942 to 0.12654, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1449 - acc: 0.4777 - val_loss: 0.1265 - val_acc: 0.5182\n",
      "Epoch 11/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.4829Epoch 00010: val_loss improved from 0.12654 to 0.12355, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1416 - acc: 0.4831 - val_loss: 0.1235 - val_acc: 0.5249\n",
      "Epoch 12/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.4863- ETA: 0s - loss: 0Epoch 00011: val_loss improved from 0.12355 to 0.12262, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1387 - acc: 0.4864 - val_loss: 0.1226 - val_acc: 0.5270\n",
      "Epoch 13/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.4914- ETA: Epoch 00012: val_loss improved from 0.12262 to 0.11813, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1352 - acc: 0.4915 - val_loss: 0.1181 - val_acc: 0.5308\n",
      "Epoch 14/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.4967- ETA: 1s - Epoch 00013: val_loss improved from 0.11813 to 0.11528, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1311 - acc: 0.4968 - val_loss: 0.1153 - val_acc: 0.5332\n",
      "Epoch 15/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.5009Epoch 00014: val_loss improved from 0.11528 to 0.11519, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1284 - acc: 0.5010 - val_loss: 0.1152 - val_acc: 0.5348\n",
      "Epoch 16/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.5035Epoch 00015: val_loss improved from 0.11519 to 0.11141, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1258 - acc: 0.5036 - val_loss: 0.1114 - val_acc: 0.5402\n",
      "Epoch 17/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.5072Epoch 00016: val_loss improved from 0.11141 to 0.10874, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1217 - acc: 0.5073 - val_loss: 0.1087 - val_acc: 0.5421\n",
      "Epoch 18/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.513 - ETA: 0s - loss: 0.1181 - acc: 0.5134Epoch 00017: val_loss improved from 0.10874 to 0.10613, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1181 - acc: 0.5135 - val_loss: 0.1061 - val_acc: 0.5448\n",
      "Epoch 19/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.5123Epoch 00018: val_loss improved from 0.10613 to 0.10546, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1176 - acc: 0.5125 - val_loss: 0.1055 - val_acc: 0.5467\n",
      "Epoch 20/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.5168Epoch 00019: val_loss improved from 0.10546 to 0.10397, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1150 - acc: 0.5169 - val_loss: 0.1040 - val_acc: 0.5499\n",
      "Epoch 21/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.5209- ETA: 2s - loss: 0.1115 - ETA: Epoch 00020: val_loss improved from 0.10397 to 0.10115, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1114 - acc: 0.5210 - val_loss: 0.1012 - val_acc: 0.5529\n",
      "Epoch 22/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.5234Epoch 00021: val_loss improved from 0.10115 to 0.09940, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1092 - acc: 0.5235 - val_loss: 0.0994 - val_acc: 0.5526\n",
      "Epoch 23/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.5249Epoch 00022: val_loss improved from 0.09940 to 0.09926, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1067 - acc: 0.5250 - val_loss: 0.0993 - val_acc: 0.5547\n",
      "Epoch 24/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.5284Epoch 00023: val_loss improved from 0.09926 to 0.09712, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1059 - acc: 0.5286 - val_loss: 0.0971 - val_acc: 0.5577\n",
      "Epoch 25/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.5297  ETEpoch 00024: val_loss improved from 0.09712 to 0.09668, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1038 - acc: 0.5298 - val_loss: 0.0967 - val_acc: 0.5580\n",
      "Epoch 26/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.5301Epoch 00025: val_loss improved from 0.09668 to 0.09431, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.1028 - acc: 0.5301 - val_loss: 0.0943 - val_acc: 0.5607\n",
      "Epoch 27/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.5336Epoch 00026: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.1002 - acc: 0.5337 - val_loss: 0.0968 - val_acc: 0.5529\n",
      "Epoch 28/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.5348Epoch 00027: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0993 - acc: 0.5349 - val_loss: 0.0969 - val_acc: 0.5513\n",
      "Epoch 29/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.5344Epoch 00028: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0984 - acc: 0.5345 - val_loss: 0.0973 - val_acc: 0.5539\n",
      "Epoch 30/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.5373Epoch 00029: val_loss improved from 0.09431 to 0.09300, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 56s - loss: 0.0965 - acc: 0.5374 - val_loss: 0.0930 - val_acc: 0.5601\n",
      "Epoch 31/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.5371- ETA: 2s - loss: 0.0964 -Epoch 00030: val_loss improved from 0.09300 to 0.09097, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 56s - loss: 0.0966 - acc: 0.5371 - val_loss: 0.0910 - val_acc: 0.5634\n",
      "Epoch 32/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.5400Epoch 00031: val_loss did not improve\n",
      "33451/33451 [==============================] - 56s - loss: 0.0959 - acc: 0.5400 - val_loss: 0.0943 - val_acc: 0.5539\n",
      "Epoch 33/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.5412- ETA: 1s - loss: - ETA: 0s - loss: 0.Epoch 00032: val_loss improved from 0.09097 to 0.09079, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 56s - loss: 0.0932 - acc: 0.5414 - val_loss: 0.0908 - val_acc: 0.5609\n",
      "Epoch 34/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.5418Epoch 00033: val_loss improved from 0.09079 to 0.08983, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 56s - loss: 0.0929 - acc: 0.5420 - val_loss: 0.0898 - val_acc: 0.5626\n",
      "Epoch 35/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.5440- ETA: 0s - loss: 0.0912 - acc: 0.5Epoch 00034: val_loss did not improve\n",
      "33451/33451 [==============================] - 56s - loss: 0.0912 - acc: 0.5442 - val_loss: 0.0899 - val_acc: 0.5585\n",
      "Epoch 36/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.5448- ETA: 1s - loss: 0.089 - ETA: 0s - loss: 0.0Epoch 00035: val_loss improved from 0.08983 to 0.08715, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 56s - loss: 0.0899 - acc: 0.5449 - val_loss: 0.0871 - val_acc: 0.5655\n",
      "Epoch 37/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.5443- ETA: 2s - loss: 0.0894 - acc:  - ET - ETA: 0s - loss: 0.0895 - acc: 0.544Epoch 00036: val_loss did not improve\n",
      "33451/33451 [==============================] - 56s - loss: 0.0895 - acc: 0.5444 - val_loss: 0.0893 - val_acc: 0.5628\n",
      "Epoch 38/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.5473Epoch 00037: val_loss did not improve\n",
      "33451/33451 [==============================] - 56s - loss: 0.0885 - acc: 0.5475 - val_loss: 0.0885 - val_acc: 0.5642\n",
      "Epoch 39/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0879 - acc: 0.5477- ETA: 4s - loss: 0. - ETA: 3sEpoch 00038: val_loss did not improve\n",
      "33451/33451 [==============================] - 56s - loss: 0.0878 - acc: 0.5478 - val_loss: 0.0913 - val_acc: 0.5574\n",
      "Epoch 40/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.5485Epoch 00039: val_loss improved from 0.08715 to 0.08498, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 56s - loss: 0.0871 - acc: 0.5486 - val_loss: 0.0850 - val_acc: 0.5679\n",
      "Epoch 41/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.5513Epoch 00040: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0865 - acc: 0.5514 - val_loss: 0.0868 - val_acc: 0.5658\n",
      "Epoch 42/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.5507Epoch 00041: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0850 - acc: 0.5508 - val_loss: 0.0883 - val_acc: 0.5639\n",
      "Epoch 43/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.5465Epoch 00042: val_loss did not improve\n",
      "33451/33451 [==============================] - 56s - loss: 0.0882 - acc: 0.5466 - val_loss: 0.0867 - val_acc: 0.5687\n",
      "Epoch 44/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.5509Epoch 00043: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0841 - acc: 0.5510 - val_loss: 0.0866 - val_acc: 0.5685\n",
      "Epoch 45/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.5496- ETA: 6s - l - ETA: 5s - loss: 0.0866 - a - ETA: 4s - - ETA: 3s - loss:  - ETA: 0s - loss: 0.0865 Epoch 00044: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0865 - acc: 0.5497 - val_loss: 0.0867 - val_acc: 0.5663\n",
      "Epoch 46/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.5491Epoch 00045: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0858 - acc: 0.5492 - val_loss: 0.0859 - val_acc: 0.5639\n",
      "Epoch 47/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.5527Epoch 00046: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0828 - acc: 0.5528 - val_loss: 0.0867 - val_acc: 0.5682\n",
      "Epoch 48/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.5531- ETA: 1s - loss: Epoch 00047: val_loss improved from 0.08498 to 0.08407, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.0819 - acc: 0.5532 - val_loss: 0.0841 - val_acc: 0.5679\n",
      "Epoch 49/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.5542Epoch 00048: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0821 - acc: 0.5543 - val_loss: 0.0851 - val_acc: 0.5685\n",
      "Epoch 50/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.5530Epoch 00049: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0825 - acc: 0.5530 - val_loss: 0.0849 - val_acc: 0.5660\n",
      "Epoch 51/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.5556- ETA: 2s - loss: 0.0808 -  - ETA: 1Epoch 00050: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0809 - acc: 0.5557 - val_loss: 0.0842 - val_acc: 0.5647\n",
      "Epoch 52/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.5540Epoch 00051: val_loss improved from 0.08407 to 0.08273, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.0810 - acc: 0.5541 - val_loss: 0.0827 - val_acc: 0.5687\n",
      "Epoch 53/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.5561Epoch 00052: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0799 - acc: 0.5562 - val_loss: 0.1336 - val_acc: 0.5211\n",
      "Epoch 54/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.5533- ETA: 1s - loss: Epoch 00053: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0828 - acc: 0.5534 - val_loss: 0.0840 - val_acc: 0.5687\n",
      "Epoch 55/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.5580Epoch 00054: val_loss did not improve\n",
      "33451/33451 [==============================] - 56s - loss: 0.0782 - acc: 0.5581 - val_loss: 0.0853 - val_acc: 0.5679\n",
      "Epoch 56/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.5572Epoch 00055: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0787 - acc: 0.5573 - val_loss: 0.0855 - val_acc: 0.5687\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.5551Epoch 00056: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0796 - acc: 0.5552 - val_loss: 0.0842 - val_acc: 0.5690\n",
      "Epoch 58/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.5568Epoch 00057: val_loss improved from 0.08273 to 0.08233, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.0785 - acc: 0.5569 - val_loss: 0.0823 - val_acc: 0.5698\n",
      "Epoch 59/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.5581Epoch 00058: val_loss improved from 0.08233 to 0.08153, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.0772 - acc: 0.5582 - val_loss: 0.0815 - val_acc: 0.5704\n",
      "Epoch 60/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.5585- ETA: 1s - loss: 0.07 - ETA: 0s - loss: 0.Epoch 00059: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0771 - acc: 0.5585 - val_loss: 0.0817 - val_acc: 0.5712\n",
      "Epoch 61/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.5595Epoch 00060: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0770 - acc: 0.5597 - val_loss: 0.0855 - val_acc: 0.5682\n",
      "Epoch 62/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.5610- ETA - ETA: 1sEpoch 00061: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0759 - acc: 0.5611 - val_loss: 0.0820 - val_acc: 0.5698\n",
      "Epoch 63/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.5571Epoch 00062: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0776 - acc: 0.5571 - val_loss: 0.0818 - val_acc: 0.5701\n",
      "Epoch 64/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.5590Epoch 00063: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0752 - acc: 0.5591 - val_loss: 0.0856 - val_acc: 0.5634\n",
      "Epoch 65/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.5579Epoch 00064: val_loss improved from 0.08153 to 0.07954, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.0776 - acc: 0.5580 - val_loss: 0.0795 - val_acc: 0.5736\n",
      "Epoch 66/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.5612- ETA: 0s - loss: 0.0739 - acEpoch 00065: val_loss improved from 0.07954 to 0.07855, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.0740 - acc: 0.5613 - val_loss: 0.0785 - val_acc: 0.5763\n",
      "Epoch 67/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.5629Epoch 00066: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0745 - acc: 0.5629 - val_loss: 0.0822 - val_acc: 0.5687\n",
      "Epoch 68/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.5607Epoch 00067: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0743 - acc: 0.5608 - val_loss: 0.0824 - val_acc: 0.5685\n",
      "Epoch 69/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.5594Epoch 00068: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0753 - acc: 0.5595 - val_loss: 0.0807 - val_acc: 0.5687\n",
      "Epoch 70/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.5599- ETA: 2s - loss: 0.0749 - ETA: 1s - loss: 0.0749 - acc: 0.560 - ETA: 1s - Epoch 00069: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0749 - acc: 0.5600 - val_loss: 0.0802 - val_acc: 0.5730\n",
      "Epoch 71/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.5598- ETA: 2s - loss: 0.0758Epoch 00070: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0758 - acc: 0.5599 - val_loss: 0.0804 - val_acc: 0.5698\n",
      "Epoch 72/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.5597Epoch 00071: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0759 - acc: 0.5598 - val_loss: 0.0801 - val_acc: 0.5714\n",
      "Epoch 73/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.5625- ETA: 5s - loss: 0.0736 - acc: 0. - Epoch 00072: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0738 - acc: 0.5626 - val_loss: 0.0790 - val_acc: 0.5722\n",
      "Epoch 74/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.5614- ETA: 1s - loss:Epoch 00073: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0741 - acc: 0.5614 - val_loss: 0.0789 - val_acc: 0.5722\n",
      "Epoch 75/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.5638Epoch 00074: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0723 - acc: 0.5639 - val_loss: 0.0793 - val_acc: 0.5709\n",
      "Epoch 76/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.5637Epoch 00075: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0722 - acc: 0.5638 - val_loss: 0.0802 - val_acc: 0.5706\n",
      "Epoch 77/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.5607Epoch 00076: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0723 - acc: 0.5608 - val_loss: 0.0801 - val_acc: 0.5714\n",
      "Epoch 78/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.5636Epoch 00077: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0720 - acc: 0.5637 - val_loss: 0.0787 - val_acc: 0.5747\n",
      "Epoch 79/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.5640Epoch 00078: val_loss improved from 0.07855 to 0.07804, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.0714 - acc: 0.5641 - val_loss: 0.0780 - val_acc: 0.5720\n",
      "Epoch 80/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.5651Epoch 00079: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0710 - acc: 0.5652 - val_loss: 0.0793 - val_acc: 0.5741\n",
      "Epoch 81/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.5618- ETA: 4s - - ETA: 3s - loss: 0.0730 - acc - ETA: 0s - loss: 0.073Epoch 00080: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0731 - acc: 0.5619 - val_loss: 0.0790 - val_acc: 0.5733\n",
      "Epoch 82/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.5629Epoch 00081: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0718 - acc: 0.5630 - val_loss: 0.0790 - val_acc: 0.5736\n",
      "Epoch 83/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.5624Epoch 00082: val_loss did not improve\n",
      "33451/33451 [==============================] - 56s - loss: 0.0729 - acc: 0.5625 - val_loss: 0.0791 - val_acc: 0.5704\n",
      "Epoch 84/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.5654Epoch 00083: val_loss improved from 0.07804 to 0.07797, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 55s - loss: 0.0701 - acc: 0.5655 - val_loss: 0.0780 - val_acc: 0.5706\n",
      "Epoch 85/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.5653- ETA:Epoch 00084: val_loss did not improve\n",
      "33451/33451 [==============================] - 56s - loss: 0.0697 - acc: 0.5654 - val_loss: 0.0780 - val_acc: 0.5730\n",
      "Epoch 86/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.5606Epoch 00085: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0747 - acc: 0.5606 - val_loss: 0.0786 - val_acc: 0.5720\n",
      "Epoch 87/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.5641Epoch 00086: val_loss improved from 0.07797 to 0.07732, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 56s - loss: 0.0714 - acc: 0.5642 - val_loss: 0.0773 - val_acc: 0.5763\n",
      "Epoch 88/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.5639Epoch 00087: val_loss did not improve\n",
      "33451/33451 [==============================] - 56s - loss: 0.0716 - acc: 0.5640 - val_loss: 0.0789 - val_acc: 0.5736\n",
      "Epoch 89/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.5624Epoch 00088: val_loss did not improve\n",
      "33451/33451 [==============================] - 56s - loss: 0.0730 - acc: 0.5624 - val_loss: 0.0786 - val_acc: 0.5709\n",
      "Epoch 90/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.5643- E - ETA: 3s - loEpoch 00089: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0699 - acc: 0.5644 - val_loss: 0.0783 - val_acc: 0.5709\n",
      "Epoch 91/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.5643- ETA: 0s - loss: 0Epoch 00090: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0703 - acc: 0.5644 - val_loss: 0.0775 - val_acc: 0.5725\n",
      "Epoch 92/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.5657- ETA: 1s  - ETA: 0s - loss: 0.0689 - acc: 0.5656Epoch 00091: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0689 - acc: 0.5657 - val_loss: 0.0790 - val_acc: 0.5679\n",
      "Epoch 93/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.5666Epoch 00092: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0689 - acc: 0.5667 - val_loss: 0.0786 - val_acc: 0.5722\n",
      "Epoch 94/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.5656- ETA - ETA: 0s - loss: 0.0695 - acc: 0.5Epoch 00093: val_loss improved from 0.07732 to 0.07661, saving model to full_model.hdf5\n",
      "33451/33451 [==============================] - 56s - loss: 0.0695 - acc: 0.5657 - val_loss: 0.0766 - val_acc: 0.5722\n",
      "Epoch 95/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.5673Epoch 00094: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0681 - acc: 0.5674 - val_loss: 0.0779 - val_acc: 0.5690\n",
      "Epoch 96/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.5660- ETA: 1s - loss: 0.0684 - acc:  - ETA: 0s - loss: 0.068Epoch 00095: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0685 - acc: 0.5661 - val_loss: 0.0785 - val_acc: 0.5709\n",
      "Epoch 97/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.5661Epoch 00096: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0685 - acc: 0.5662 - val_loss: 0.0789 - val_acc: 0.5706\n",
      "Epoch 98/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.5658Epoch 00097: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0688 - acc: 0.5659 - val_loss: 0.0794 - val_acc: 0.5682\n",
      "Epoch 99/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.5631Epoch 00098: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0712 - acc: 0.5632 - val_loss: 0.1331 - val_acc: 0.5679\n",
      "Epoch 100/100\n",
      "33440/33451 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.5645Epoch 00099: val_loss did not improve\n",
      "33451/33451 [==============================] - 55s - loss: 0.0710 - acc: 0.5646 - val_loss: 0.0792 - val_acc: 0.5720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6f26c28e48>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit_generator(train_generator, samples_per_epoch=len(train_raw_inputs), callbacks=callback_list,nb_epoch=100, \n",
    "               validation_data=validation_generator, nb_val_samples=len(validation_raw_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## FINAL RESULTS\n",
    "\n",
    "The best model is renamed in the root folder **best_model.hdf5**\n",
    "\n",
    "My model is able to complete the drive of the easy route with max speed at 20. \n",
    "\n",
    "However, it is only able to complete the difficult drive with the max speed of 12. Due to the sharp turns that the model is not able to deal with at such high speed. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
