{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Network to Drive Car in Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "######\n",
    "CENTER_IDX = 0\n",
    "LEFT_IDX = 1\n",
    "RIGHT_IDX = 2\n",
    "STEERING_ANGLE_IDX = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READ INPUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_file_name(file):\n",
    "    \"\"\"\n",
    "    Assume last backslash\n",
    "    \"\"\"\n",
    "    assert(file is not None)\n",
    "    name_start = file.rfind(\"/\")\n",
    "    return file[name_start+1:]\n",
    "\n",
    "\n",
    "def read_input_dir(folder_name, center_imgs, left_imgs, right_imgs, steering_angles):\n",
    "    # OPEN data folder to read data\n",
    "    # load csv file\n",
    "    if not os.path.exists(folder_name):\n",
    "        raise Exception('folder %s does not exist' % folder_name)\n",
    "    with open(folder_name + \"/driving_log.csv\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for data in reader:\n",
    "            # extract name \n",
    "            left_img = os.path.join(folder_name+\"/IMG\", extract_file_name(data[LEFT_IDX]))\n",
    "            right_img = os.path.join(folder_name+\"/IMG\", extract_file_name(data[RIGHT_IDX]))\n",
    "            center_img = os.path.join(folder_name+\"/IMG\", extract_file_name(data[CENTER_IDX]))\n",
    "            # append data \n",
    "            left_imgs.append(left_img)\n",
    "            right_imgs.append(right_img)\n",
    "            center_imgs.append(center_img)\n",
    "            steering_angles.append(float(data[STEERING_ANGLE_IDX]))\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ ALL DATA FOLDER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2797 2797\n",
      "5893 5893\n",
      "6867 6867\n",
      "8360 8360\n",
      "9330 9330\n",
      "10560 10560\n",
      "11652 11652\n",
      "13738 13738\n",
      "15090 15090\n"
     ]
    }
   ],
   "source": [
    "center_imgs = []\n",
    "left_imgs = []\n",
    "right_imgs = []\n",
    "steering_angles = []\n",
    "# read each data folder\n",
    "read_input_dir(\"../collect_data/drive_forward_data\", center_imgs, left_imgs, right_imgs, steering_angles)\n",
    "print (len(center_imgs), len(steering_angles))\n",
    "read_input_dir(\"../collect_data/drive_reverse_data\", center_imgs, left_imgs, right_imgs, steering_angles)\n",
    "print (len(center_imgs), len(steering_angles))\n",
    "read_input_dir(\"../collect_data/drive_left_data\", center_imgs, left_imgs, right_imgs, steering_angles)\n",
    "print (len(center_imgs), len(steering_angles))\n",
    "read_input_dir(\"../collect_data/drive_right_data\", center_imgs, left_imgs, right_imgs, steering_angles)\n",
    "print (len(center_imgs), len(steering_angles))\n",
    "read_input_dir(\"../collect_data2/side_drive_data_1\", center_imgs, left_imgs, right_imgs, steering_angles)\n",
    "print (len(center_imgs), len(steering_angles))\n",
    "read_input_dir(\"../collect_data2/side_drive_data2\", center_imgs, left_imgs, right_imgs, steering_angles)\n",
    "print (len(center_imgs), len(steering_angles))\n",
    "read_input_dir(\"../collect_data3/bridge_data\", center_imgs, left_imgs, right_imgs, steering_angles)\n",
    "print (len(center_imgs), len(steering_angles))\n",
    "read_input_dir(\"../collect_data4\", center_imgs, left_imgs, right_imgs, steering_angles)\n",
    "print (len(center_imgs), len(steering_angles))\n",
    "read_input_dir(\"../collect_data5\", center_imgs, left_imgs, right_imgs, steering_angles)\n",
    "print (len(center_imgs), len(steering_angles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "import numpy as np\n",
    "center_imgs = np.array(center_imgs)\n",
    "left_imgs = np.array(left_imgs)\n",
    "right_imgs = np.array(right_imgs)\n",
    "steering_angles = np.array(steering_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ RAW IMAGE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_inputs = []\n",
    "raw_labels = []\n",
    "# CENTEER\n",
    "for i, image_path in enumerate(center_imgs):\n",
    "    if (not os.path.exists(image_path)):\n",
    "        print(\"Failed %s \" % image_path)\n",
    "    raw_inputs.append(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n",
    "    raw_labels.append(steering_angles[i])\n",
    "# for i, image_path in enumerate(left_imgs):\n",
    "#     if (not os.path.exists(image_path)):\n",
    "#         print(\"Failed %s \" % image_path)\n",
    "#     raw_inputs.append(cv2.imread(image_path))\n",
    "#     raw_labels.append(steering_angles[i] - 0.3)\n",
    "# for i, image_path in enumerate(right_imgs):\n",
    "#     if (not os.path.exists(image_path)):\n",
    "#         print(\"Failed %s \" % image_path)\n",
    "#     raw_inputs.append(cv2.imread(image_path))\n",
    "#     raw_labels.append(steering_angles[i] + 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15090, 160, 320, 3)\n",
      "(15090,)\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = np.array(raw_inputs)\n",
    "raw_labels = np.array(raw_labels)\n",
    "print(raw_inputs.shape)\n",
    "print(raw_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NETWORK ARCHITECTURE AND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dropout, MaxPooling2D, Dense, Lambda, Cropping2D\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    # normalize input \n",
    "    model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))\n",
    "    model.add(Cropping2D(cropping=((70,25),(0,0)))) \n",
    "    model.add(Conv2D(24, 5, 5,activation='relu', subsample=(2,2))) # input: 65x320x3, 31x158x3x16\n",
    "    model.add(Dropout(p=0.2))\n",
    "    model.add(Conv2D(36, 5, 5,activation='relu',subsample=(2,2))) # input: 31x158x3x32, 13x76x3x32 \n",
    "    model.add(Dropout(p=0.2))\n",
    "    model.add(Conv2D(48, 5, 5,activation='relu',subsample=(2,2))) # input: 31x158x3x32, 13x76x3x32 \n",
    "    model.add(Dropout(p=0.2))\n",
    "    model.add(Conv2D(64, 3, 3,activation='relu')) # input: 31x158x3x32, 13x76x3x32 \n",
    "    model.add(Dropout(p=0.2))\n",
    "    model.add(Conv2D(64, 3, 3,activation='relu')) # input: 31x158x3x32, 13x76x3x32 \n",
    "    model.add(Dropout(p=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dropout(p=0.4))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"best_model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callback_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12072 samples, validate on 3018 samples\n",
      "Epoch 1/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.5981Epoch 00000: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0331 - acc: 0.5980 - val_loss: 0.1631 - val_acc: 0.3903\n",
      "Epoch 2/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.5996Epoch 00001: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0307 - acc: 0.5994 - val_loss: 0.1592 - val_acc: 0.3827\n",
      "Epoch 3/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.6002Epoch 00002: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0290 - acc: 0.6001 - val_loss: 0.1668 - val_acc: 0.3757\n",
      "Epoch 4/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.6000Epoch 00003: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0274 - acc: 0.5999 - val_loss: 0.1591 - val_acc: 0.3840\n",
      "Epoch 5/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.6006Epoch 00004: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0265 - acc: 0.6006 - val_loss: 0.1612 - val_acc: 0.3880\n",
      "Epoch 6/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.6003Epoch 00005: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0248 - acc: 0.6003 - val_loss: 0.1569 - val_acc: 0.3860\n",
      "Epoch 7/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.6009Epoch 00006: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0236 - acc: 0.6010 - val_loss: 0.1686 - val_acc: 0.3754\n",
      "Epoch 8/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.6005Epoch 00007: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0238 - acc: 0.6006 - val_loss: 0.1674 - val_acc: 0.3860\n",
      "Epoch 9/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.6021Epoch 00008: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0226 - acc: 0.6018 - val_loss: 0.1631 - val_acc: 0.3814\n",
      "Epoch 10/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.6016Epoch 00009: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0216 - acc: 0.6016 - val_loss: 0.1579 - val_acc: 0.3883\n",
      "Epoch 11/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.6021Epoch 00010: val_acc did not improve\n",
      "12072/12072 [==============================] - 13s - loss: 0.0204 - acc: 0.6023 - val_loss: 0.1626 - val_acc: 0.3850\n",
      "Epoch 12/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.6015Epoch 00011: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0201 - acc: 0.6016 - val_loss: 0.1679 - val_acc: 0.3777\n",
      "Epoch 13/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.6022Epoch 00012: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0196 - acc: 0.6023 - val_loss: 0.1660 - val_acc: 0.3685\n",
      "Epoch 14/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.6015Epoch 00013: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0196 - acc: 0.6016 - val_loss: 0.1637 - val_acc: 0.3804\n",
      "Epoch 15/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.6020Epoch 00014: val_acc did not improve\n",
      "12072/12072 [==============================] - 13s - loss: 0.0185 - acc: 0.6019 - val_loss: 0.1553 - val_acc: 0.3923\n",
      "Epoch 16/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.6022Epoch 00015: val_acc did not improve\n",
      "12072/12072 [==============================] - 13s - loss: 0.0173 - acc: 0.6021 - val_loss: 0.1603 - val_acc: 0.3830\n",
      "Epoch 17/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.6020Epoch 00016: val_acc did not improve\n",
      "12072/12072 [==============================] - 13s - loss: 0.0172 - acc: 0.6022 - val_loss: 0.1666 - val_acc: 0.3801\n",
      "Epoch 18/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.6019Epoch 00017: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0174 - acc: 0.6021 - val_loss: 0.1599 - val_acc: 0.3834\n",
      "Epoch 19/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.6026Epoch 00018: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0170 - acc: 0.6026 - val_loss: 0.1681 - val_acc: 0.3801\n",
      "Epoch 20/20\n",
      "12064/12072 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.6024Epoch 00019: val_acc did not improve\n",
      "12072/12072 [==============================] - 12s - loss: 0.0166 - acc: 0.6024 - val_loss: 0.1595 - val_acc: 0.3860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f69ece86dd8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(raw_inputs, raw_labels, validation_split=0.2, shuffle=True, batch_size=32, callbacks=callback_list, nb_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
